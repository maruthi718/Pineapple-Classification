{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: opencv-python in c:\\users\\gmrit\\anaconda3\\lib\\site-packages (4.8.0.74)\n","Requirement already satisfied: numpy>=1.17.0; python_version >= \"3.7\" in c:\\users\\gmrit\\anaconda3\\lib\\site-packages (from opencv-python) (1.21.6)\n","Note: you may need to restart the kernel to use updated packages.\n"]},{"name":"stderr","output_type":"stream","text":["Keyring is skipped due to an exception: 'keyring.backends'\n"]}],"source":["\n","pip install opencv-python\n"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["import os\n","import cv2 as cv\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import os\n","import cv2\n","import pandas as pd\n","import numpy as np\n","\n","def load_images_from_folder(folder_path, label):\n","    images = []\n","    labels = []\n","    for filename in os.listdir(folder_path):\n","        img = os.path.join(folder_path, filename)\n","        # if img is not None:\n","        #     img = cv2.resize(img, (227, 227))  # Resize the images to match the input shape of AlexNet\n","        #     img=np.array(img)\n","        images.append(img)\n","        labels.append(label)\n","    return images, labels\n","\n","# Define the two folders containing the images and their corresponding labels\n","folder_path_classA = r\"C:\\Users\\GMRIT\\Desktop\\pineapple577\\DATA\\RAW\"\n","folder_path_classB = r\"C:\\Users\\GMRIT\\Desktop\\pineapple577\\DATA\\RIPE\"\n","\n","# Load images and labels for classA\n","images_classA, labels_classA = load_images_from_folder(folder_path_classA, label=\"Raw\")\n","\n","# Load images and labels for classB\n","images_classB, labels_classB = load_images_from_folder(folder_path_classB, label=\"Ripe\")\n","\n","# Combine the data from both classes into a single DataFrame\n","data = {\n","    \"image\": images_classA + images_classB,\n","    \"label\": labels_classA + labels_classB\n","}\n","\n","df = pd.DataFrame(data)\n","\n","# Shuffle the DataFrame (optional)\n","df = df.sample(frac=1).reset_index(drop=True)\n","\n","# Now, the DataFrame 'df' contains the image data and corresponding labels from both folders.\n","# You can use this DataFrame for further processing or training your model.\n"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>image</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>C:\\Users\\GMRIT\\Desktop\\pineapple577\\DATA\\RAW\\r...</td>\n","      <td>Raw</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>C:\\Users\\GMRIT\\Desktop\\pineapple577\\DATA\\RAW\\r...</td>\n","      <td>Raw</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>C:\\Users\\GMRIT\\Desktop\\pineapple577\\DATA\\RIPE\\...</td>\n","      <td>Ripe</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>C:\\Users\\GMRIT\\Desktop\\pineapple577\\DATA\\RAW\\r...</td>\n","      <td>Raw</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>C:\\Users\\GMRIT\\Desktop\\pineapple577\\DATA\\RIPE\\...</td>\n","      <td>Ripe</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1299</th>\n","      <td>C:\\Users\\GMRIT\\Desktop\\pineapple577\\DATA\\RIPE\\...</td>\n","      <td>Ripe</td>\n","    </tr>\n","    <tr>\n","      <th>1300</th>\n","      <td>C:\\Users\\GMRIT\\Desktop\\pineapple577\\DATA\\RIPE\\...</td>\n","      <td>Ripe</td>\n","    </tr>\n","    <tr>\n","      <th>1301</th>\n","      <td>C:\\Users\\GMRIT\\Desktop\\pineapple577\\DATA\\RIPE\\...</td>\n","      <td>Ripe</td>\n","    </tr>\n","    <tr>\n","      <th>1302</th>\n","      <td>C:\\Users\\GMRIT\\Desktop\\pineapple577\\DATA\\RIPE\\...</td>\n","      <td>Ripe</td>\n","    </tr>\n","    <tr>\n","      <th>1303</th>\n","      <td>C:\\Users\\GMRIT\\Desktop\\pineapple577\\DATA\\RIPE\\...</td>\n","      <td>Ripe</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1304 rows Ã— 2 columns</p>\n","</div>"],"text/plain":["                                                  image label\n","0     C:\\Users\\GMRIT\\Desktop\\pineapple577\\DATA\\RAW\\r...   Raw\n","1     C:\\Users\\GMRIT\\Desktop\\pineapple577\\DATA\\RAW\\r...   Raw\n","2     C:\\Users\\GMRIT\\Desktop\\pineapple577\\DATA\\RIPE\\...  Ripe\n","3     C:\\Users\\GMRIT\\Desktop\\pineapple577\\DATA\\RAW\\r...   Raw\n","4     C:\\Users\\GMRIT\\Desktop\\pineapple577\\DATA\\RIPE\\...  Ripe\n","...                                                 ...   ...\n","1299  C:\\Users\\GMRIT\\Desktop\\pineapple577\\DATA\\RIPE\\...  Ripe\n","1300  C:\\Users\\GMRIT\\Desktop\\pineapple577\\DATA\\RIPE\\...  Ripe\n","1301  C:\\Users\\GMRIT\\Desktop\\pineapple577\\DATA\\RIPE\\...  Ripe\n","1302  C:\\Users\\GMRIT\\Desktop\\pineapple577\\DATA\\RIPE\\...  Ripe\n","1303  C:\\Users\\GMRIT\\Desktop\\pineapple577\\DATA\\RIPE\\...  Ripe\n","\n","[1304 rows x 2 columns]"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["df"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["                                                  image label  encoded_label\n","0     C:\\Users\\GMRIT\\Desktop\\pineapple577\\DATA\\RAW\\r...   Raw              0\n","1     C:\\Users\\GMRIT\\Desktop\\pineapple577\\DATA\\RAW\\r...   Raw              0\n","2     C:\\Users\\GMRIT\\Desktop\\pineapple577\\DATA\\RIPE\\...  Ripe              1\n","3     C:\\Users\\GMRIT\\Desktop\\pineapple577\\DATA\\RAW\\r...   Raw              0\n","4     C:\\Users\\GMRIT\\Desktop\\pineapple577\\DATA\\RIPE\\...  Ripe              1\n","...                                                 ...   ...            ...\n","1299  C:\\Users\\GMRIT\\Desktop\\pineapple577\\DATA\\RIPE\\...  Ripe              1\n","1300  C:\\Users\\GMRIT\\Desktop\\pineapple577\\DATA\\RIPE\\...  Ripe              1\n","1301  C:\\Users\\GMRIT\\Desktop\\pineapple577\\DATA\\RIPE\\...  Ripe              1\n","1302  C:\\Users\\GMRIT\\Desktop\\pineapple577\\DATA\\RIPE\\...  Ripe              1\n","1303  C:\\Users\\GMRIT\\Desktop\\pineapple577\\DATA\\RIPE\\...  Ripe              1\n","\n","[1304 rows x 3 columns]\n"]}],"source":["from sklearn.preprocessing import LabelEncoder\n","# Create an instance of LabelEncoder\n","label_encoder = LabelEncoder()\n","\n","# Fit and transform the labels in the DataFrame\n","df[\"encoded_label\"] = label_encoder.fit_transform(df[\"label\"])\n","\n","print(df)\n"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["# earlystopping = tf.keras.callbacks.EarlyStopping(\n","#     monitor=\"val_loss\",\n","#     min_delta=0.001,\n","#     # patience=2,\n","#     verbose=1,\n","#     mode=\"auto\",\n","#     baseline=None,\n","#     restore_best_weights=False,\n","# )"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"]},{"name":"stdout","output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," vgg16 (Functional)          (None, 7, 7, 512)         14714688  \n","                                                                 \n"," flatten (Flatten)           (None, 25088)             0         \n","                                                                 \n"," dense (Dense)               (None, 256)               6422784   \n","                                                                 \n"," dropout (Dropout)           (None, 256)               0         \n","                                                                 \n"," dense_1 (Dense)             (None, 1)                 257       \n","                                                                 \n","=================================================================\n","Total params: 21,137,729\n","Trainable params: 6,423,041\n","Non-trainable params: 14,714,688\n","_________________________________________________________________\n"]}],"source":["from tensorflow.keras.applications import VGG16\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Flatten, Dropout\n","from tensorflow.keras.optimizers import Adam\n","\n","# Load the pre-trained VGG16 model (excluding the top classification layers)\n","vgg_base = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n","\n","# Freeze the weights of the VGG16 base (optional)\n","for layer in vgg_base.layers:\n","    layer.trainable = False\n","\n","# Create a new model\n","model = Sequential()\n","\n","# Add the VGG16 base\n","model.add(vgg_base)\n","\n","# Add custom layers for binary classification\n","model.add(Flatten())\n","model.add(Dense(256, activation='relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(1, activation='sigmoid'))\n","\n","# Compile the model\n","model.compile(loss='binary_crossentropy',\n","              optimizer=Adam(lr=0.01),\n","              metrics=['accuracy'])\n","\n","# Print the summary of the model architecture\n","model.summary()\n"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","from PIL import Image\n","from sklearn.model_selection import train_test_split\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n","from tensorflow.keras.utils import to_categorical\n"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["def load_and_preprocess_image(image_path, image_width, image_height):\n","    image = Image.open(image_path)\n","    image = image.resize((image_width, image_height))\n","    image_array = np.array(image) / 255.0\n","    return image_array"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["X = np.array([load_and_preprocess_image(str(path), 224,224) for path in df['image']])\n","y = df['encoded_label'] "]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/15\n","11/11 [==============================] - 85s 8s/step - loss: 2.0705 - accuracy: 0.6769 - val_loss: 0.8927 - val_accuracy: 0.7816\n","Epoch 2/15\n","11/11 [==============================] - 83s 8s/step - loss: 0.7170 - accuracy: 0.7804 - val_loss: 0.3557 - val_accuracy: 0.8774\n","Epoch 3/15\n","11/11 [==============================] - 87s 8s/step - loss: 0.3975 - accuracy: 0.8533 - val_loss: 0.3429 - val_accuracy: 0.8697\n","Epoch 4/15\n","11/11 [==============================] - 84s 8s/step - loss: 0.2945 - accuracy: 0.8849 - val_loss: 0.3086 - val_accuracy: 0.8736\n","Epoch 5/15\n","11/11 [==============================] - 84s 8s/step - loss: 0.2365 - accuracy: 0.9051 - val_loss: 0.3395 - val_accuracy: 0.8851\n","Epoch 6/15\n","11/11 [==============================] - 84s 8s/step - loss: 0.2116 - accuracy: 0.9118 - val_loss: 0.2889 - val_accuracy: 0.8736\n","Epoch 7/15\n","11/11 [==============================] - 86s 8s/step - loss: 0.1870 - accuracy: 0.9262 - val_loss: 0.2846 - val_accuracy: 0.8774\n","Epoch 8/15\n","11/11 [==============================] - 84s 8s/step - loss: 0.1582 - accuracy: 0.9453 - val_loss: 0.2836 - val_accuracy: 0.8966\n","Epoch 9/15\n","11/11 [==============================] - 84s 8s/step - loss: 0.1435 - accuracy: 0.9521 - val_loss: 0.2827 - val_accuracy: 0.8966\n","Epoch 10/15\n","11/11 [==============================] - 84s 8s/step - loss: 0.1300 - accuracy: 0.9597 - val_loss: 0.3070 - val_accuracy: 0.8927\n","Epoch 11/15\n","11/11 [==============================] - 84s 8s/step - loss: 0.1169 - accuracy: 0.9597 - val_loss: 0.2802 - val_accuracy: 0.8697\n","Epoch 12/15\n","11/11 [==============================] - 83s 8s/step - loss: 0.1061 - accuracy: 0.9626 - val_loss: 0.2739 - val_accuracy: 0.8889\n","Epoch 13/15\n","11/11 [==============================] - 84s 8s/step - loss: 0.0859 - accuracy: 0.9789 - val_loss: 0.2884 - val_accuracy: 0.8889\n","Epoch 14/15\n","11/11 [==============================] - 84s 8s/step - loss: 0.0811 - accuracy: 0.9808 - val_loss: 0.2841 - val_accuracy: 0.8812\n","Epoch 15/15\n","11/11 [==============================] - 83s 8s/step - loss: 0.0706 - accuracy: 0.9818 - val_loss: 0.2919 - val_accuracy: 0.8736\n"]},{"data":{"text/plain":["<keras.callbacks.History at 0x1626d5a8cc8>"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["\n","model.fit(X,y, batch_size=100, epochs=15, validation_split=0.2)\n"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["model.save('vggORG_model1.h5')"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["import os"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["import os\n","import cv2\n","import pandas as pd\n","import numpy as np\n","\n","def load_images_from_folder(folder_path, label):\n","    images = []\n","    labels = []\n","    for filename in os.listdir(folder_path):\n","        img = os.path.join(folder_path, filename)\n","        # if img is not None:\n","        #     img = cv2.resize(img, (227, 227))  # Resize the images to match the input shape of AlexNet\n","        #     img=np.array(img)\n","        images.append(img)\n","        labels.append(label)\n","    return images, labels\n","\n","# Define the two folders containing the images and their corresponding labels\n","folder_path_classA = r\"C:\\Users\\GMRIT\\Desktop\\pineapple577\\results\\DATA\\RAW\"\n","folder_path_classB = r\"C:\\Users\\GMRIT\\Desktop\\pineapple577\\results\\DATA\\RIPE\"\n","\n","# Load images and labels for classA\n","images_classA, labels_classA = load_images_from_folder(folder_path_classA, label=\"Raw\")\n","\n","# Load images and labels for classB\n","images_classB, labels_classB = load_images_from_folder(folder_path_classB, label=\"Ripe\")\n","\n","# Combine the data from both classes into a single DataFrame\n","data = {\n","    \"image\": images_classA + images_classB,\n","    \"label\": labels_classA + labels_classB\n","}\n","\n","df = pd.DataFrame(data)\n","\n","# Shuffle the DataFrame (optional)\n","df = df.sample(frac=1).reset_index(drop=True)\n","\n","# Now, the DataFrame 'df' contains the image data and corresponding labels from both folders.\n","# You can use this DataFrame for further processing or training your model.\n"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["                                                 image label  encoded_label\n","0    C:\\Users\\GMRIT\\Desktop\\pineapple577\\results\\DA...   Raw              0\n","1    C:\\Users\\GMRIT\\Desktop\\pineapple577\\results\\DA...   Raw              0\n","2    C:\\Users\\GMRIT\\Desktop\\pineapple577\\results\\DA...  Ripe              1\n","3    C:\\Users\\GMRIT\\Desktop\\pineapple577\\results\\DA...  Ripe              1\n","4    C:\\Users\\GMRIT\\Desktop\\pineapple577\\results\\DA...  Ripe              1\n","..                                                 ...   ...            ...\n","140  C:\\Users\\GMRIT\\Desktop\\pineapple577\\results\\DA...   Raw              0\n","141  C:\\Users\\GMRIT\\Desktop\\pineapple577\\results\\DA...   Raw              0\n","142  C:\\Users\\GMRIT\\Desktop\\pineapple577\\results\\DA...  Ripe              1\n","143  C:\\Users\\GMRIT\\Desktop\\pineapple577\\results\\DA...  Ripe              1\n","144  C:\\Users\\GMRIT\\Desktop\\pineapple577\\results\\DA...  Ripe              1\n","\n","[145 rows x 3 columns]\n"]}],"source":["from sklearn.preprocessing import LabelEncoder\n","# Create an instance of LabelEncoder\n","label_encoder = LabelEncoder()\n","\n","# Fit and transform the labels in the DataFrame\n","df[\"encoded_label\"] = label_encoder.fit_transform(df[\"label\"])\n","\n","print(df)\n"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["Xt = np.array([load_and_preprocess_image(str(path), 224,224) for path in df['image']])\n","yt = df['encoded_label'] "]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["5/5 [==============================] - 9s 2s/step\n"]}],"source":["from tensorflow.keras.models import load_model\n","\n","# Load the model from the H5 file\n","loaded_model = load_model('vggORG_model1.h5')\n","\n","# Now, you can use the loaded_model to make predictions on new data\n","# For example:\n","import numpy as np\n","\n","# Assuming you have new data stored in the 'new_data' variable\n","predictions = loaded_model.predict(Xt)\n","\n","# 'predictions' will contain the model's output for the new data\n","# You can now use 'predictions' for further processing or analysis\n"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[[2.09958047e-01]\n"," [4.03484106e-01]\n"," [9.86290038e-01]\n"," [9.58417892e-01]\n"," [7.23986924e-01]\n"," [9.78009775e-03]\n"," [8.28532219e-01]\n"," [8.13259959e-01]\n"," [1.63700283e-01]\n"," [2.12935265e-02]\n"," [9.56498623e-01]\n"," [9.04024601e-01]\n"," [6.74709260e-01]\n"," [9.81558502e-01]\n"," [8.52522671e-01]\n"," [6.56157553e-01]\n"," [2.84180433e-01]\n"," [8.78275037e-01]\n"," [8.01562965e-01]\n"," [9.93569717e-02]\n"," [9.92140710e-01]\n"," [7.29488254e-01]\n"," [7.65578926e-01]\n"," [1.56199802e-02]\n"," [6.30589485e-01]\n"," [8.66713762e-01]\n"," [6.65246665e-01]\n"," [9.35274959e-01]\n"," [7.55162328e-04]\n"," [9.10609901e-01]\n"," [1.94756500e-02]\n"," [5.71129732e-02]\n"," [6.88260019e-01]\n"," [9.02546197e-02]\n"," [9.88518000e-01]\n"," [6.94666326e-01]\n"," [9.02037621e-01]\n"," [9.12072957e-01]\n"," [3.82622451e-01]\n"," [3.80894303e-01]\n"," [6.34693861e-01]\n"," [1.28090410e-02]\n"," [7.68764138e-01]\n"," [5.28628044e-02]\n"," [7.64839888e-01]\n"," [9.51520145e-01]\n"," [5.33026585e-04]\n"," [1.70761589e-02]\n"," [8.99857998e-01]\n"," [9.77314353e-01]\n"," [9.87700403e-01]\n"," [6.04871511e-01]\n"," [9.75245833e-01]\n"," [1.55527350e-02]\n"," [4.42863435e-01]\n"," [8.89371634e-01]\n"," [3.80313926e-04]\n"," [8.39358926e-01]\n"," [9.98132825e-01]\n"," [9.69096720e-01]\n"," [5.95285177e-01]\n"," [9.47024703e-01]\n"," [2.32777782e-02]\n"," [9.65365529e-01]\n"," [6.83847889e-02]\n"," [9.26033974e-01]\n"," [3.70575964e-01]\n"," [6.36752741e-03]\n"," [5.92049630e-03]\n"," [9.98205304e-01]\n"," [4.86289337e-02]\n"," [9.20365989e-01]\n"," [6.51125237e-02]\n"," [7.35703766e-01]\n"," [9.70691860e-01]\n"," [7.44161546e-01]\n"," [1.15501426e-01]\n"," [3.19899589e-01]\n"," [9.54478800e-01]\n"," [9.99123096e-01]\n"," [9.96011913e-01]\n"," [1.36264146e-03]\n"," [6.78915679e-01]\n"," [7.38203758e-03]\n"," [9.82435107e-01]\n"," [4.42585677e-01]\n"," [2.31279746e-01]\n"," [7.82115579e-01]\n"," [9.53415990e-01]\n"," [5.14903069e-01]\n"," [8.30684662e-01]\n"," [7.51384487e-03]\n"," [5.67382574e-01]\n"," [8.94939184e-01]\n"," [5.19486796e-03]\n"," [9.87545729e-01]\n"," [9.54151809e-01]\n"," [6.01063907e-01]\n"," [5.16569674e-01]\n"," [1.07434988e-01]\n"," [9.30467844e-01]\n"," [1.79401413e-01]\n"," [9.24919009e-01]\n"," [7.28828609e-01]\n"," [6.57885611e-01]\n"," [8.59985113e-01]\n"," [9.95305538e-01]\n"," [9.73390579e-01]\n"," [9.95497644e-01]\n"," [9.67809856e-01]\n"," [9.40813363e-01]\n"," [6.29222929e-01]\n"," [3.04978574e-03]\n"," [8.44739437e-01]\n"," [6.02055620e-03]\n"," [3.91088426e-02]\n"," [3.11417133e-01]\n"," [1.57427322e-02]\n"," [9.81786847e-01]\n"," [2.64172722e-02]\n"," [1.15002804e-02]\n"," [7.37229168e-01]\n"," [9.54588413e-01]\n"," [5.81860662e-01]\n"," [6.96903765e-01]\n"," [1.16161313e-02]\n"," [4.07253094e-02]\n"," [4.25363690e-01]\n"," [2.58434238e-03]\n"," [9.96893525e-01]\n"," [9.27067339e-01]\n"," [1.45017326e-01]\n"," [9.34481025e-01]\n"," [9.16233718e-01]\n"," [5.26330054e-01]\n"," [8.46818328e-01]\n"," [9.38276947e-01]\n"," [3.06790834e-03]\n"," [6.67552988e-04]\n"," [9.81153488e-01]\n"," [5.87823629e-01]\n"," [5.16341859e-03]\n"," [9.59811985e-01]\n"," [9.45807546e-02]\n"," [9.62089062e-01]]\n"]},{"data":{"text/plain":["145"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["\n","\n","print(predictions)\n","predictions.size"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[],"source":["from sklearn.metrics import classification_report"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Continuous Targets: [[2.09958047e-01]\n"," [4.03484106e-01]\n"," [9.86290038e-01]\n"," [9.58417892e-01]\n"," [7.23986924e-01]\n"," [9.78009775e-03]\n"," [8.28532219e-01]\n"," [8.13259959e-01]\n"," [1.63700283e-01]\n"," [2.12935265e-02]\n"," [9.56498623e-01]\n"," [9.04024601e-01]\n"," [6.74709260e-01]\n"," [9.81558502e-01]\n"," [8.52522671e-01]\n"," [6.56157553e-01]\n"," [2.84180433e-01]\n"," [8.78275037e-01]\n"," [8.01562965e-01]\n"," [9.93569717e-02]\n"," [9.92140710e-01]\n"," [7.29488254e-01]\n"," [7.65578926e-01]\n"," [1.56199802e-02]\n"," [6.30589485e-01]\n"," [8.66713762e-01]\n"," [6.65246665e-01]\n"," [9.35274959e-01]\n"," [7.55162328e-04]\n"," [9.10609901e-01]\n"," [1.94756500e-02]\n"," [5.71129732e-02]\n"," [6.88260019e-01]\n"," [9.02546197e-02]\n"," [9.88518000e-01]\n"," [6.94666326e-01]\n"," [9.02037621e-01]\n"," [9.12072957e-01]\n"," [3.82622451e-01]\n"," [3.80894303e-01]\n"," [6.34693861e-01]\n"," [1.28090410e-02]\n"," [7.68764138e-01]\n"," [5.28628044e-02]\n"," [7.64839888e-01]\n"," [9.51520145e-01]\n"," [5.33026585e-04]\n"," [1.70761589e-02]\n"," [8.99857998e-01]\n"," [9.77314353e-01]\n"," [9.87700403e-01]\n"," [6.04871511e-01]\n"," [9.75245833e-01]\n"," [1.55527350e-02]\n"," [4.42863435e-01]\n"," [8.89371634e-01]\n"," [3.80313926e-04]\n"," [8.39358926e-01]\n"," [9.98132825e-01]\n"," [9.69096720e-01]\n"," [5.95285177e-01]\n"," [9.47024703e-01]\n"," [2.32777782e-02]\n"," [9.65365529e-01]\n"," [6.83847889e-02]\n"," [9.26033974e-01]\n"," [3.70575964e-01]\n"," [6.36752741e-03]\n"," [5.92049630e-03]\n"," [9.98205304e-01]\n"," [4.86289337e-02]\n"," [9.20365989e-01]\n"," [6.51125237e-02]\n"," [7.35703766e-01]\n"," [9.70691860e-01]\n"," [7.44161546e-01]\n"," [1.15501426e-01]\n"," [3.19899589e-01]\n"," [9.54478800e-01]\n"," [9.99123096e-01]\n"," [9.96011913e-01]\n"," [1.36264146e-03]\n"," [6.78915679e-01]\n"," [7.38203758e-03]\n"," [9.82435107e-01]\n"," [4.42585677e-01]\n"," [2.31279746e-01]\n"," [7.82115579e-01]\n"," [9.53415990e-01]\n"," [5.14903069e-01]\n"," [8.30684662e-01]\n"," [7.51384487e-03]\n"," [5.67382574e-01]\n"," [8.94939184e-01]\n"," [5.19486796e-03]\n"," [9.87545729e-01]\n"," [9.54151809e-01]\n"," [6.01063907e-01]\n"," [5.16569674e-01]\n"," [1.07434988e-01]\n"," [9.30467844e-01]\n"," [1.79401413e-01]\n"," [9.24919009e-01]\n"," [7.28828609e-01]\n"," [6.57885611e-01]\n"," [8.59985113e-01]\n"," [9.95305538e-01]\n"," [9.73390579e-01]\n"," [9.95497644e-01]\n"," [9.67809856e-01]\n"," [9.40813363e-01]\n"," [6.29222929e-01]\n"," [3.04978574e-03]\n"," [8.44739437e-01]\n"," [6.02055620e-03]\n"," [3.91088426e-02]\n"," [3.11417133e-01]\n"," [1.57427322e-02]\n"," [9.81786847e-01]\n"," [2.64172722e-02]\n"," [1.15002804e-02]\n"," [7.37229168e-01]\n"," [9.54588413e-01]\n"," [5.81860662e-01]\n"," [6.96903765e-01]\n"," [1.16161313e-02]\n"," [4.07253094e-02]\n"," [4.25363690e-01]\n"," [2.58434238e-03]\n"," [9.96893525e-01]\n"," [9.27067339e-01]\n"," [1.45017326e-01]\n"," [9.34481025e-01]\n"," [9.16233718e-01]\n"," [5.26330054e-01]\n"," [8.46818328e-01]\n"," [9.38276947e-01]\n"," [3.06790834e-03]\n"," [6.67552988e-04]\n"," [9.81153488e-01]\n"," [5.87823629e-01]\n"," [5.16341859e-03]\n"," [9.59811985e-01]\n"," [9.45807546e-02]\n"," [9.62089062e-01]]\n","Binary Targets: [[1]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [0]\n"," [1]\n"," [1]\n"," [0]\n"," [0]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [0]\n"," [1]\n"," [1]\n"," [1]\n"," [0]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [0]\n"," [1]\n"," [0]\n"," [0]\n"," [1]\n"," [0]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [0]\n"," [1]\n"," [0]\n"," [1]\n"," [1]\n"," [0]\n"," [0]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [0]\n"," [1]\n"," [1]\n"," [0]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [0]\n"," [1]\n"," [0]\n"," [1]\n"," [1]\n"," [0]\n"," [0]\n"," [1]\n"," [0]\n"," [1]\n"," [0]\n"," [1]\n"," [1]\n"," [1]\n"," [0]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [0]\n"," [1]\n"," [0]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [0]\n"," [1]\n"," [1]\n"," [0]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [0]\n"," [1]\n"," [0]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [0]\n"," [1]\n"," [0]\n"," [0]\n"," [1]\n"," [0]\n"," [1]\n"," [0]\n"," [0]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [0]\n"," [0]\n"," [1]\n"," [0]\n"," [1]\n"," [1]\n"," [0]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [0]\n"," [0]\n"," [1]\n"," [1]\n"," [0]\n"," [1]\n"," [0]\n"," [1]]\n"]}],"source":["# Set the threshold value\n","threshold = 0.2\n","\n","# Apply thresholding to convert to binary targets\n","pred = (predictions > threshold).astype(int)\n","\n","print(\"Continuous Targets:\", predictions)\n","print(\"Binary Targets:\", pred)\n"]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.83      0.69      0.75        51\n","           1       0.84      0.93      0.88        94\n","\n","    accuracy                           0.84       145\n","   macro avg       0.84      0.81      0.82       145\n","weighted avg       0.84      0.84      0.84       145\n","\n"]}],"source":["# Create a classification report\n","report = classification_report(yt, pred)\n","\n","# Print the classification report\n","print(report)"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["1/1 [==============================] - 0s 201ms/step\n"]}],"source":["predict = loaded_model.predict(np.array([load_and_preprocess_image(str(r\"C:\\Users\\GMRIT\\Desktop\\pineapple577\\ripe.jpg\"), 227,227)]))\n"]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[{"data":{"text/plain":["array([[0.5355567]], dtype=float32)"]},"execution_count":30,"metadata":{},"output_type":"execute_result"}],"source":["predict"]},{"cell_type":"code","execution_count":31,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: visualkeras in c:\\users\\gmrit\\anaconda3\\lib\\site-packages (0.0.2)\n","Requirement already satisfied: aggdraw>=1.3.11 in c:\\users\\gmrit\\anaconda3\\lib\\site-packages (from visualkeras) (1.3.16)\n","Requirement already satisfied: pillow>=6.2.0 in c:\\users\\gmrit\\anaconda3\\lib\\site-packages (from visualkeras) (7.0.0)\n","Requirement already satisfied: numpy>=1.18.1 in c:\\users\\gmrit\\anaconda3\\lib\\site-packages (from visualkeras) (1.21.6)\n","Note: you may need to restart the kernel to use updated packages.\n"]},{"name":"stderr","output_type":"stream","text":["Keyring is skipped due to an exception: 'keyring.backends'\n"]}],"source":["pip install visualkeras\n"]},{"cell_type":"code","execution_count":32,"metadata":{},"outputs":[{"data":{"image/png":"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","text/plain":["<PIL.Image.Image image mode=RGBA size=591x38 at 0x1626E9986C8>"]},"execution_count":32,"metadata":{},"output_type":"execute_result"}],"source":["import visualkeras\n","visualkeras.layered_view(model)"]},{"cell_type":"code","execution_count":33,"metadata":{},"outputs":[{"data":{"image/png":"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","text/plain":["<PIL.Image.Image image mode=RGBA size=591x74 at 0x1626E99F608>"]},"execution_count":33,"metadata":{},"output_type":"execute_result"}],"source":["visualkeras.layered_view(model, legend=True) # without custom font"]},{"cell_type":"code","execution_count":34,"metadata":{},"outputs":[{"data":{"image/png":"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","text/plain":["<PIL.Image.Image image mode=RGBA size=591x77 at 0x1626E99F708>"]},"execution_count":34,"metadata":{},"output_type":"execute_result"}],"source":["from PIL import ImageFont\n","font = ImageFont.truetype(\"arial.ttf\", 12)\n","visualkeras.layered_view(model, legend=True, font=font) # selected font"]},{"cell_type":"code","execution_count":35,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Model summary saved to 'inception_model_summary.txt'.\n"]}],"source":["# Save the model summary to a text file\n","with open('VGGORG_model_summary.txt', 'w') as f:\n","    loaded_model.summary(print_fn=lambda x: f.write(x + '\\n'))\n","\n","print(\"Model summary saved to 'inception_model_summary.txt'.\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"}},"nbformat":4,"nbformat_minor":4}
