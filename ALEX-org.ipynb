{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: opencv-python in c:\\users\\gmrit\\anaconda3\\lib\\site-packages (4.8.0.74)\n","Requirement already satisfied: numpy>=1.17.0; python_version >= \"3.7\" in c:\\users\\gmrit\\anaconda3\\lib\\site-packages (from opencv-python) (1.21.6)\n","Note: you may need to restart the kernel to use updated packages.\n"]},{"name":"stderr","output_type":"stream","text":["Keyring is skipped due to an exception: 'keyring.backends'\n"]}],"source":["\n","pip install opencv-python\n"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["import os\n","import cv2 as cv\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import os\n","import cv2\n","import pandas as pd\n","import numpy as np\n","\n","def load_images_from_folder(folder_path, label):\n","    images = []\n","    labels = []\n","    for filename in os.listdir(folder_path):\n","        img = os.path.join(folder_path, filename)\n","        # if img is not None:\n","        #     img = cv2.resize(img, (227, 227))  # Resize the images to match the input shape of AlexNet\n","        #     img=np.array(img)\n","        images.append(img)\n","        labels.append(label)\n","    return images, labels\n","\n","# Define the two folders containing the images and their corresponding labels\n","folder_path_classA = r\"C:\\Users\\GMRIT\\Desktop\\pineapple577\\DATA\\RAW\"\n","folder_path_classB = r\"C:\\Users\\GMRIT\\Desktop\\pineapple577\\DATA\\RIPE\"\n","\n","# Load images and labels for classA\n","images_classA, labels_classA = load_images_from_folder(folder_path_classA, label=\"Raw\")\n","\n","# Load images and labels for classB\n","images_classB, labels_classB = load_images_from_folder(folder_path_classB, label=\"Ripe\")\n","\n","# Combine the data from both classes into a single DataFrame\n","data = {\n","    \"image\": images_classA + images_classB,\n","    \"label\": labels_classA + labels_classB\n","}\n","\n","df = pd.DataFrame(data)\n","\n","# Shuffle the DataFrame (optional)\n","df = df.sample(frac=1).reset_index(drop=True)\n","\n","# Now, the DataFrame 'df' contains the image data and corresponding labels from both folders.\n","# You can use this DataFrame for further processing or training your model.\n"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>image</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>C:\\Users\\GMRIT\\Desktop\\pineapple577\\DATA\\RIPE\\...</td>\n","      <td>Ripe</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>C:\\Users\\GMRIT\\Desktop\\pineapple577\\DATA\\RIPE\\...</td>\n","      <td>Ripe</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>C:\\Users\\GMRIT\\Desktop\\pineapple577\\DATA\\RIPE\\...</td>\n","      <td>Ripe</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>C:\\Users\\GMRIT\\Desktop\\pineapple577\\DATA\\RAW\\r...</td>\n","      <td>Raw</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>C:\\Users\\GMRIT\\Desktop\\pineapple577\\DATA\\RIPE\\...</td>\n","      <td>Ripe</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1299</th>\n","      <td>C:\\Users\\GMRIT\\Desktop\\pineapple577\\DATA\\RAW\\r...</td>\n","      <td>Raw</td>\n","    </tr>\n","    <tr>\n","      <th>1300</th>\n","      <td>C:\\Users\\GMRIT\\Desktop\\pineapple577\\DATA\\RAW\\r...</td>\n","      <td>Raw</td>\n","    </tr>\n","    <tr>\n","      <th>1301</th>\n","      <td>C:\\Users\\GMRIT\\Desktop\\pineapple577\\DATA\\RIPE\\...</td>\n","      <td>Ripe</td>\n","    </tr>\n","    <tr>\n","      <th>1302</th>\n","      <td>C:\\Users\\GMRIT\\Desktop\\pineapple577\\DATA\\RAW\\r...</td>\n","      <td>Raw</td>\n","    </tr>\n","    <tr>\n","      <th>1303</th>\n","      <td>C:\\Users\\GMRIT\\Desktop\\pineapple577\\DATA\\RAW\\r...</td>\n","      <td>Raw</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1304 rows Ã— 2 columns</p>\n","</div>"],"text/plain":["                                                  image label\n","0     C:\\Users\\GMRIT\\Desktop\\pineapple577\\DATA\\RIPE\\...  Ripe\n","1     C:\\Users\\GMRIT\\Desktop\\pineapple577\\DATA\\RIPE\\...  Ripe\n","2     C:\\Users\\GMRIT\\Desktop\\pineapple577\\DATA\\RIPE\\...  Ripe\n","3     C:\\Users\\GMRIT\\Desktop\\pineapple577\\DATA\\RAW\\r...   Raw\n","4     C:\\Users\\GMRIT\\Desktop\\pineapple577\\DATA\\RIPE\\...  Ripe\n","...                                                 ...   ...\n","1299  C:\\Users\\GMRIT\\Desktop\\pineapple577\\DATA\\RAW\\r...   Raw\n","1300  C:\\Users\\GMRIT\\Desktop\\pineapple577\\DATA\\RAW\\r...   Raw\n","1301  C:\\Users\\GMRIT\\Desktop\\pineapple577\\DATA\\RIPE\\...  Ripe\n","1302  C:\\Users\\GMRIT\\Desktop\\pineapple577\\DATA\\RAW\\r...   Raw\n","1303  C:\\Users\\GMRIT\\Desktop\\pineapple577\\DATA\\RAW\\r...   Raw\n","\n","[1304 rows x 2 columns]"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["df"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["                                                  image label  encoded_label\n","0     C:\\Users\\GMRIT\\Desktop\\pineapple577\\DATA\\RIPE\\...  Ripe              1\n","1     C:\\Users\\GMRIT\\Desktop\\pineapple577\\DATA\\RIPE\\...  Ripe              1\n","2     C:\\Users\\GMRIT\\Desktop\\pineapple577\\DATA\\RIPE\\...  Ripe              1\n","3     C:\\Users\\GMRIT\\Desktop\\pineapple577\\DATA\\RAW\\r...   Raw              0\n","4     C:\\Users\\GMRIT\\Desktop\\pineapple577\\DATA\\RIPE\\...  Ripe              1\n","...                                                 ...   ...            ...\n","1299  C:\\Users\\GMRIT\\Desktop\\pineapple577\\DATA\\RAW\\r...   Raw              0\n","1300  C:\\Users\\GMRIT\\Desktop\\pineapple577\\DATA\\RAW\\r...   Raw              0\n","1301  C:\\Users\\GMRIT\\Desktop\\pineapple577\\DATA\\RIPE\\...  Ripe              1\n","1302  C:\\Users\\GMRIT\\Desktop\\pineapple577\\DATA\\RAW\\r...   Raw              0\n","1303  C:\\Users\\GMRIT\\Desktop\\pineapple577\\DATA\\RAW\\r...   Raw              0\n","\n","[1304 rows x 3 columns]\n"]}],"source":["from sklearn.preprocessing import LabelEncoder\n","# Create an instance of LabelEncoder\n","label_encoder = LabelEncoder()\n","\n","# Fit and transform the labels in the DataFrame\n","df[\"encoded_label\"] = label_encoder.fit_transform(df[\"label\"])\n","\n","print(df)\n"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["# earlystopping = tf.keras.callbacks.EarlyStopping(\n","#     monitor=\"val_loss\",\n","#     min_delta=0.001,\n","#     # patience=2,\n","#     verbose=1,\n","#     mode=\"auto\",\n","#     baseline=None,\n","#     restore_best_weights=False,\n","# )"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential_2\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d_10 (Conv2D)          (None, 55, 55, 96)        34944     \n","                                                                 \n"," max_pooling2d_6 (MaxPooling  (None, 27, 27, 96)       0         \n"," 2D)                                                             \n","                                                                 \n"," batch_normalization_10 (Bat  (None, 27, 27, 96)       384       \n"," chNormalization)                                                \n","                                                                 \n"," conv2d_11 (Conv2D)          (None, 27, 27, 256)       614656    \n","                                                                 \n"," max_pooling2d_7 (MaxPooling  (None, 13, 13, 256)      0         \n"," 2D)                                                             \n","                                                                 \n"," batch_normalization_11 (Bat  (None, 13, 13, 256)      1024      \n"," chNormalization)                                                \n","                                                                 \n"," conv2d_12 (Conv2D)          (None, 13, 13, 384)       885120    \n","                                                                 \n"," batch_normalization_12 (Bat  (None, 13, 13, 384)      1536      \n"," chNormalization)                                                \n","                                                                 \n"," conv2d_13 (Conv2D)          (None, 13, 13, 384)       1327488   \n","                                                                 \n"," batch_normalization_13 (Bat  (None, 13, 13, 384)      1536      \n"," chNormalization)                                                \n","                                                                 \n"," conv2d_14 (Conv2D)          (None, 13, 13, 256)       884992    \n","                                                                 \n"," max_pooling2d_8 (MaxPooling  (None, 6, 6, 256)        0         \n"," 2D)                                                             \n","                                                                 \n"," batch_normalization_14 (Bat  (None, 6, 6, 256)        1024      \n"," chNormalization)                                                \n","                                                                 \n"," flatten_2 (Flatten)         (None, 9216)              0         \n","                                                                 \n"," dense_6 (Dense)             (None, 4096)              37752832  \n","                                                                 \n"," dropout_4 (Dropout)         (None, 4096)              0         \n","                                                                 \n"," dense_7 (Dense)             (None, 4096)              16781312  \n","                                                                 \n"," dropout_5 (Dropout)         (None, 4096)              0         \n","                                                                 \n"," dense_8 (Dense)             (None, 1)                 4097      \n","                                                                 \n","=================================================================\n","Total params: 58,290,945\n","Trainable params: 58,288,193\n","Non-trainable params: 2,752\n","_________________________________________________________________\n"]}],"source":["import tensorflow as tf\n","from tensorflow.keras import layers, models\n","from tensorflow.keras.optimizers import Adam\n","def AlexNet(input_shape, num_classes):\n","    model = models.Sequential()\n","\n","    # Layer 1\n","    model.add(layers.Conv2D(96, kernel_size=(11, 11), strides=(4, 4), padding='valid', activation='relu', input_shape=input_shape))\n","    model.add(layers.MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='valid'))\n","    model.add(layers.BatchNormalization())\n","\n","    # Layer 2\n","    model.add(layers.Conv2D(256, kernel_size=(5, 5), strides=(1, 1), padding='same', activation='relu'))\n","    model.add(layers.MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='valid'))\n","    model.add(layers.BatchNormalization())\n","\n","    # Layer 3\n","    model.add(layers.Conv2D(384, kernel_size=(3, 3), strides=(1, 1), padding='same', activation='relu'))\n","    model.add(layers.BatchNormalization())\n","\n","    # Layer 4\n","    model.add(layers.Conv2D(384, kernel_size=(3, 3), strides=(1, 1), padding='same', activation='relu'))\n","    model.add(layers.BatchNormalization())\n","\n","    # Layer 5\n","    model.add(layers.Conv2D(256, kernel_size=(3, 3), strides=(1, 1), padding='same', activation='relu'))\n","    model.add(layers.MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='valid'))\n","    model.add(layers.BatchNormalization())\n","\n","    # Flatten the output for fully connected layers\n","    model.add(layers.Flatten())\n","\n","    # Layer 6\n","    model.add(layers.Dense(4096, activation='relu'))\n","    model.add(layers.Dropout(0.5))\n","\n","    # Layer 7\n","    model.add(layers.Dense(4096, activation='relu'))\n","    model.add(layers.Dropout(0.5))\n","\n","    # Output layer\n","    model.add(layers.Dense(num_classes, activation='sigmoid'))\n","\n","    return model\n","\n","# Define input shape and number of classes\n","input_shape = (227, 227, 3)  # Adjust input shape according to your images\n","num_classes = 1  # Adjust the number of classes based on your dataset\n","\n","# Create the AlexNet model\n","model = AlexNet(input_shape, num_classes)\n","\n","# Print the model summary\n","model.summary()\n"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[],"source":["# Compile the model\n","model.compile(loss='binary_crossentropy',\n","              optimizer=Adam(learning_rate=0.001),\n","              metrics=['accuracy'])"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","from PIL import Image\n","from sklearn.model_selection import train_test_split\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n","from tensorflow.keras.utils import to_categorical\n"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["def load_and_preprocess_image(image_path, image_width, image_height):\n","    image = Image.open(image_path)\n","    image = image.resize((image_width, image_height))\n","    image_array = np.array(image) / 255.0\n","    return image_array"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["X = np.array([load_and_preprocess_image(str(path), 227,227) for path in df['image']])\n","y = df['encoded_label'] "]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/20\n","11/11 [==============================] - 36s 3s/step - loss: 0.2571 - accuracy: 0.8926 - val_loss: 1.2662 - val_accuracy: 0.8659\n","Epoch 2/20\n","11/11 [==============================] - 27s 2s/step - loss: 0.2456 - accuracy: 0.8849 - val_loss: 1.0865 - val_accuracy: 0.8582\n","Epoch 3/20\n","11/11 [==============================] - 27s 2s/step - loss: 0.2471 - accuracy: 0.8849 - val_loss: 1.7593 - val_accuracy: 0.8429\n","Epoch 4/20\n","11/11 [==============================] - 27s 2s/step - loss: 0.2352 - accuracy: 0.8945 - val_loss: 2.3357 - val_accuracy: 0.8621\n","Epoch 5/20\n","11/11 [==============================] - 27s 2s/step - loss: 0.2180 - accuracy: 0.8945 - val_loss: 1.4879 - val_accuracy: 0.8582\n","Epoch 6/20\n","11/11 [==============================] - 27s 2s/step - loss: 0.2388 - accuracy: 0.8878 - val_loss: 1.4298 - val_accuracy: 0.8544\n","Epoch 7/20\n","11/11 [==============================] - 27s 2s/step - loss: 0.2447 - accuracy: 0.8792 - val_loss: 1.2143 - val_accuracy: 0.8621\n","Epoch 8/20\n","11/11 [==============================] - 27s 2s/step - loss: 0.2141 - accuracy: 0.9089 - val_loss: 1.6549 - val_accuracy: 0.8774\n","Epoch 9/20\n","11/11 [==============================] - 27s 2s/step - loss: 0.2291 - accuracy: 0.9022 - val_loss: 1.8909 - val_accuracy: 0.8697\n","Epoch 10/20\n","11/11 [==============================] - 27s 2s/step - loss: 0.2733 - accuracy: 0.8878 - val_loss: 0.8675 - val_accuracy: 0.8238\n","Epoch 11/20\n","11/11 [==============================] - 27s 2s/step - loss: 0.2975 - accuracy: 0.8686 - val_loss: 0.9177 - val_accuracy: 0.8467\n","Epoch 12/20\n","11/11 [==============================] - 28s 3s/step - loss: 0.2433 - accuracy: 0.8878 - val_loss: 1.0659 - val_accuracy: 0.8391\n","Epoch 13/20\n","11/11 [==============================] - 27s 3s/step - loss: 0.2148 - accuracy: 0.8878 - val_loss: 0.9899 - val_accuracy: 0.8506\n","Epoch 14/20\n","11/11 [==============================] - 27s 2s/step - loss: 0.2184 - accuracy: 0.8945 - val_loss: 0.6125 - val_accuracy: 0.8697\n","Epoch 15/20\n","11/11 [==============================] - 27s 2s/step - loss: 0.2018 - accuracy: 0.9022 - val_loss: 0.4959 - val_accuracy: 0.8736\n","Epoch 16/20\n","11/11 [==============================] - 27s 2s/step - loss: 0.2016 - accuracy: 0.9022 - val_loss: 0.5337 - val_accuracy: 0.8582\n","Epoch 17/20\n","11/11 [==============================] - 27s 2s/step - loss: 0.1854 - accuracy: 0.9022 - val_loss: 0.7280 - val_accuracy: 0.8659\n","Epoch 18/20\n","11/11 [==============================] - 27s 2s/step - loss: 0.1988 - accuracy: 0.9099 - val_loss: 0.7419 - val_accuracy: 0.8697\n","Epoch 19/20\n","11/11 [==============================] - 27s 2s/step - loss: 0.1728 - accuracy: 0.9051 - val_loss: 0.8627 - val_accuracy: 0.8697\n","Epoch 20/20\n","11/11 [==============================] - 27s 2s/step - loss: 0.1708 - accuracy: 0.9175 - val_loss: 0.8914 - val_accuracy: 0.8736\n"]},{"data":{"text/plain":["<keras.callbacks.History at 0x12fa2ffed08>"]},"execution_count":24,"metadata":{},"output_type":"execute_result"}],"source":["\n","model.fit(X,y, batch_size=100, epochs=20, validation_split=0.2)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model.save('ALEXORG_model1.h5')"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["import os"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import os\n","import cv2\n","import pandas as pd\n","import numpy as np\n","\n","def load_images_from_folder(folder_path, label):\n","    images = []\n","    labels = []\n","    for filename in os.listdir(folder_path):\n","        img = os.path.join(folder_path, filename)\n","        # if img is not None:\n","        #     img = cv2.resize(img, (227, 227))  # Resize the images to match the input shape of AlexNet\n","        #     img=np.array(img)\n","        images.append(img)\n","        labels.append(label)\n","    return images, labels\n","\n","# Define the two folders containing the images and their corresponding labels\n","folder_path_classA = r\"C:\\Users\\GMRIT\\Desktop\\pineapple577\\results\\DATA\\RAW\"\n","folder_path_classB = r\"C:\\Users\\GMRIT\\Desktop\\pineapple577\\results\\DATA\\RIPE\"\n","\n","# Load images and labels for classA\n","images_classA, labels_classA = load_images_from_folder(folder_path_classA, label=\"Raw\")\n","\n","# Load images and labels for classB\n","images_classB, labels_classB = load_images_from_folder(folder_path_classB, label=\"Ripe\")\n","\n","# Combine the data from both classes into a single DataFrame\n","data = {\n","    \"image\": images_classA + images_classB,\n","    \"label\": labels_classA + labels_classB\n","}\n","\n","df = pd.DataFrame(data)\n","\n","# Shuffle the DataFrame (optional)\n","df = df.sample(frac=1).reset_index(drop=True)\n","\n","# Now, the DataFrame 'df' contains the image data and corresponding labels from both folders.\n","# You can use this DataFrame for further processing or training your model.\n"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["                                                 image label  encoded_label\n","0    C:\\Users\\GMRIT\\Desktop\\pineapple577\\results\\DA...  Ripe              1\n","1    C:\\Users\\GMRIT\\Desktop\\pineapple577\\results\\DA...   Raw              0\n","2    C:\\Users\\GMRIT\\Desktop\\pineapple577\\results\\DA...  Ripe              1\n","3    C:\\Users\\GMRIT\\Desktop\\pineapple577\\results\\DA...  Ripe              1\n","4    C:\\Users\\GMRIT\\Desktop\\pineapple577\\results\\DA...   Raw              0\n","..                                                 ...   ...            ...\n","140  C:\\Users\\GMRIT\\Desktop\\pineapple577\\results\\DA...   Raw              0\n","141  C:\\Users\\GMRIT\\Desktop\\pineapple577\\results\\DA...   Raw              0\n","142  C:\\Users\\GMRIT\\Desktop\\pineapple577\\results\\DA...  Ripe              1\n","143  C:\\Users\\GMRIT\\Desktop\\pineapple577\\results\\DA...   Raw              0\n","144  C:\\Users\\GMRIT\\Desktop\\pineapple577\\results\\DA...  Ripe              1\n","\n","[145 rows x 3 columns]\n"]}],"source":["from sklearn.preprocessing import LabelEncoder\n","# Create an instance of LabelEncoder\n","label_encoder = LabelEncoder()\n","\n","# Fit and transform the labels in the DataFrame\n","df[\"encoded_label\"] = label_encoder.fit_transform(df[\"label\"])\n","\n","print(df)\n"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["Xt = np.array([load_and_preprocess_image(str(path), 227,227) for path in df['image']])\n","yt = df['encoded_label'] "]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["5/5 [==============================] - 1s 132ms/step\n"]}],"source":["from tensorflow.keras.models import load_model\n","\n","# Load the model from the H5 file\n","loaded_model = load_model('ALEXORG_model1.h5')\n","\n","# Now, you can use the loaded_model to make predictions on new data\n","# For example:\n","import numpy as np\n","\n","# Assuming you have new data stored in the 'new_data' variable\n","predictions = loaded_model.predict(Xt)\n","\n","# 'predictions' will contain the model's output for the new data\n","# You can now use 'predictions' for further processing or analysis\n"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[[9.98411715e-01]\n"," [4.81228679e-02]\n"," [1.00000000e+00]\n"," [5.57573709e-10]\n"," [1.00000000e+00]\n"," [2.25458324e-23]\n"," [9.89529550e-01]\n"," [5.76694629e-06]\n"," [9.99967396e-01]\n"," [1.77117336e-33]\n"," [5.19060344e-02]\n"," [9.49847400e-01]\n"," [7.74304152e-01]\n"," [4.69384879e-01]\n"," [8.79338530e-15]\n"," [6.37422233e-12]\n"," [1.08105246e-21]\n"," [9.80853140e-01]\n"," [9.82488215e-01]\n"," [9.56393600e-01]\n"," [9.99913573e-01]\n"," [1.19650751e-01]\n"," [6.09117448e-01]\n"," [3.61382306e-01]\n"," [9.99999821e-01]\n"," [1.12984355e-09]\n"," [9.87226546e-01]\n"," [5.45222406e-07]\n"," [1.00000000e+00]\n"," [9.85030949e-01]\n"," [3.01131345e-02]\n"," [9.94671702e-01]\n"," [6.54800236e-01]\n"," [9.99792576e-01]\n"," [9.68874199e-04]\n"," [9.99960363e-01]\n"," [5.04617008e-11]\n"," [6.09117448e-01]\n"," [9.97938156e-01]\n"," [9.97487962e-01]\n"," [7.31637537e-01]\n"," [9.95995045e-01]\n"," [7.75316596e-01]\n"," [1.06333643e-10]\n"," [7.59523174e-12]\n"," [1.13960137e-33]\n"," [2.17215259e-07]\n"," [4.44824807e-02]\n"," [1.23530599e-08]\n"," [4.16177227e-06]\n"," [8.51360738e-01]\n"," [9.90446746e-01]\n"," [9.74647939e-01]\n"," [8.18841100e-01]\n"," [6.09117448e-01]\n"," [8.63176137e-02]\n"," [1.84465423e-01]\n"," [1.37826228e-05]\n"," [1.55652398e-08]\n"," [6.15517398e-19]\n"," [4.93941069e-01]\n"," [7.98217058e-01]\n"," [9.82524633e-01]\n"," [8.64273131e-01]\n"," [2.46638101e-15]\n"," [7.80829191e-01]\n"," [4.85671580e-01]\n"," [1.81385309e-01]\n"," [8.79858315e-01]\n"," [1.00000000e+00]\n"," [9.88724232e-01]\n"," [1.00000000e+00]\n"," [8.33550697e-17]\n"," [3.54495266e-17]\n"," [7.26236987e-11]\n"," [7.05647409e-01]\n"," [9.95120287e-01]\n"," [4.02812575e-11]\n"," [3.43599916e-02]\n"," [1.00000000e+00]\n"," [9.75730300e-01]\n"," [9.92709875e-01]\n"," [1.68805414e-08]\n"," [6.09117448e-01]\n"," [6.42658591e-01]\n"," [9.98868704e-01]\n"," [1.12779853e-04]\n"," [6.09117448e-01]\n"," [9.99998927e-01]\n"," [6.65089428e-01]\n"," [6.09117448e-01]\n"," [2.99996969e-07]\n"," [5.37619096e-15]\n"," [8.98395896e-01]\n"," [3.29044200e-02]\n"," [6.09117448e-01]\n"," [8.02321196e-01]\n"," [4.03417014e-02]\n"," [8.64810534e-09]\n"," [1.86939690e-06]\n"," [6.20173864e-07]\n"," [1.00000000e+00]\n"," [9.86860633e-01]\n"," [1.48459964e-08]\n"," [6.09117448e-01]\n"," [5.83564281e-01]\n"," [1.00000000e+00]\n"," [6.31452918e-01]\n"," [1.00000000e+00]\n"," [9.74605143e-01]\n"," [8.39573443e-01]\n"," [9.96033430e-01]\n"," [8.70779276e-01]\n"," [6.09117448e-01]\n"," [1.42707215e-08]\n"," [6.09117448e-01]\n"," [6.09117448e-01]\n"," [1.37654527e-10]\n"," [2.89108310e-13]\n"," [9.97867763e-01]\n"," [4.70401261e-07]\n"," [9.88958418e-01]\n"," [2.00406428e-11]\n"," [1.77897289e-01]\n"," [7.33113110e-01]\n"," [2.42877754e-19]\n"," [9.99676168e-01]\n"," [1.00000000e+00]\n"," [9.06432271e-01]\n"," [1.00000000e+00]\n"," [1.00000000e+00]\n"," [9.99774516e-01]\n"," [5.57300564e-06]\n"," [6.54722333e-01]\n"," [5.99371672e-01]\n"," [1.19173163e-15]\n"," [1.34171586e-07]\n"," [6.09117448e-01]\n"," [1.92517728e-05]\n"," [5.46410722e-14]\n"," [2.42788391e-03]\n"," [1.21358254e-15]\n"," [1.00000000e+00]\n"," [1.21047573e-11]\n"," [9.85339701e-01]]\n"]},{"data":{"text/plain":["145"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["\n","\n","print(predictions)\n","predictions.size"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["from sklearn.metrics import classification_report"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Continuous Targets: [[9.98411715e-01]\n"," [4.81228679e-02]\n"," [1.00000000e+00]\n"," [5.57573709e-10]\n"," [1.00000000e+00]\n"," [2.25458324e-23]\n"," [9.89529550e-01]\n"," [5.76694629e-06]\n"," [9.99967396e-01]\n"," [1.77117336e-33]\n"," [5.19060344e-02]\n"," [9.49847400e-01]\n"," [7.74304152e-01]\n"," [4.69384879e-01]\n"," [8.79338530e-15]\n"," [6.37422233e-12]\n"," [1.08105246e-21]\n"," [9.80853140e-01]\n"," [9.82488215e-01]\n"," [9.56393600e-01]\n"," [9.99913573e-01]\n"," [1.19650751e-01]\n"," [6.09117448e-01]\n"," [3.61382306e-01]\n"," [9.99999821e-01]\n"," [1.12984355e-09]\n"," [9.87226546e-01]\n"," [5.45222406e-07]\n"," [1.00000000e+00]\n"," [9.85030949e-01]\n"," [3.01131345e-02]\n"," [9.94671702e-01]\n"," [6.54800236e-01]\n"," [9.99792576e-01]\n"," [9.68874199e-04]\n"," [9.99960363e-01]\n"," [5.04617008e-11]\n"," [6.09117448e-01]\n"," [9.97938156e-01]\n"," [9.97487962e-01]\n"," [7.31637537e-01]\n"," [9.95995045e-01]\n"," [7.75316596e-01]\n"," [1.06333643e-10]\n"," [7.59523174e-12]\n"," [1.13960137e-33]\n"," [2.17215259e-07]\n"," [4.44824807e-02]\n"," [1.23530599e-08]\n"," [4.16177227e-06]\n"," [8.51360738e-01]\n"," [9.90446746e-01]\n"," [9.74647939e-01]\n"," [8.18841100e-01]\n"," [6.09117448e-01]\n"," [8.63176137e-02]\n"," [1.84465423e-01]\n"," [1.37826228e-05]\n"," [1.55652398e-08]\n"," [6.15517398e-19]\n"," [4.93941069e-01]\n"," [7.98217058e-01]\n"," [9.82524633e-01]\n"," [8.64273131e-01]\n"," [2.46638101e-15]\n"," [7.80829191e-01]\n"," [4.85671580e-01]\n"," [1.81385309e-01]\n"," [8.79858315e-01]\n"," [1.00000000e+00]\n"," [9.88724232e-01]\n"," [1.00000000e+00]\n"," [8.33550697e-17]\n"," [3.54495266e-17]\n"," [7.26236987e-11]\n"," [7.05647409e-01]\n"," [9.95120287e-01]\n"," [4.02812575e-11]\n"," [3.43599916e-02]\n"," [1.00000000e+00]\n"," [9.75730300e-01]\n"," [9.92709875e-01]\n"," [1.68805414e-08]\n"," [6.09117448e-01]\n"," [6.42658591e-01]\n"," [9.98868704e-01]\n"," [1.12779853e-04]\n"," [6.09117448e-01]\n"," [9.99998927e-01]\n"," [6.65089428e-01]\n"," [6.09117448e-01]\n"," [2.99996969e-07]\n"," [5.37619096e-15]\n"," [8.98395896e-01]\n"," [3.29044200e-02]\n"," [6.09117448e-01]\n"," [8.02321196e-01]\n"," [4.03417014e-02]\n"," [8.64810534e-09]\n"," [1.86939690e-06]\n"," [6.20173864e-07]\n"," [1.00000000e+00]\n"," [9.86860633e-01]\n"," [1.48459964e-08]\n"," [6.09117448e-01]\n"," [5.83564281e-01]\n"," [1.00000000e+00]\n"," [6.31452918e-01]\n"," [1.00000000e+00]\n"," [9.74605143e-01]\n"," [8.39573443e-01]\n"," [9.96033430e-01]\n"," [8.70779276e-01]\n"," [6.09117448e-01]\n"," [1.42707215e-08]\n"," [6.09117448e-01]\n"," [6.09117448e-01]\n"," [1.37654527e-10]\n"," [2.89108310e-13]\n"," [9.97867763e-01]\n"," [4.70401261e-07]\n"," [9.88958418e-01]\n"," [2.00406428e-11]\n"," [1.77897289e-01]\n"," [7.33113110e-01]\n"," [2.42877754e-19]\n"," [9.99676168e-01]\n"," [1.00000000e+00]\n"," [9.06432271e-01]\n"," [1.00000000e+00]\n"," [1.00000000e+00]\n"," [9.99774516e-01]\n"," [5.57300564e-06]\n"," [6.54722333e-01]\n"," [5.99371672e-01]\n"," [1.19173163e-15]\n"," [1.34171586e-07]\n"," [6.09117448e-01]\n"," [1.92517728e-05]\n"," [5.46410722e-14]\n"," [2.42788391e-03]\n"," [1.21358254e-15]\n"," [1.00000000e+00]\n"," [1.21047573e-11]\n"," [9.85339701e-01]]\n","Binary Targets: [[1]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [0]\n"," [1]\n"," [1]\n"," [1]\n"," [0]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [0]\n"," [0]\n"," [0]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [0]\n"," [0]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [0]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [0]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [0]\n"," [0]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [0]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [0]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [0]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [0]\n"," [1]\n"," [1]\n"," [1]\n"," [0]\n"," [1]\n"," [0]\n"," [1]\n"," [1]\n"," [1]]\n"]}],"source":["# Set the threshold value\n","threshold = 0.00000000001\n","\n","# Apply thresholding to convert to binary targets\n","pred = (predictions > threshold).astype(int)\n","\n","print(\"Continuous Targets:\", predictions)\n","print(\"Binary Targets:\", pred)\n"]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.88      0.29      0.44        51\n","           1       0.72      0.98      0.83        94\n","\n","    accuracy                           0.74       145\n","   macro avg       0.80      0.64      0.64       145\n","weighted avg       0.78      0.74      0.69       145\n","\n"]}],"source":["# Create a classification report\n","report = classification_report(yt, pred)\n","\n","# Print the classification report\n","print(report)"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["1/1 [==============================] - 0s 201ms/step\n"]}],"source":["predict = loaded_model.predict(np.array([load_and_preprocess_image(str(r\"C:\\Users\\GMRIT\\Desktop\\pineapple577\\ripe.jpg\"), 227,227)]))\n"]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[{"data":{"text/plain":["array([[0.5355567]], dtype=float32)"]},"execution_count":30,"metadata":{},"output_type":"execute_result"}],"source":["predict"]},{"cell_type":"code","execution_count":31,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: visualkeras in c:\\users\\gmrit\\anaconda3\\lib\\site-packages (0.0.2)\n","Requirement already satisfied: aggdraw>=1.3.11 in c:\\users\\gmrit\\anaconda3\\lib\\site-packages (from visualkeras) (1.3.16)\n","Requirement already satisfied: pillow>=6.2.0 in c:\\users\\gmrit\\anaconda3\\lib\\site-packages (from visualkeras) (7.0.0)\n","Requirement already satisfied: numpy>=1.18.1 in c:\\users\\gmrit\\anaconda3\\lib\\site-packages (from visualkeras) (1.21.6)\n","Note: you may need to restart the kernel to use updated packages.\n"]},{"name":"stderr","output_type":"stream","text":["Keyring is skipped due to an exception: 'keyring.backends'\n"]}],"source":["pip install visualkeras\n"]},{"cell_type":"code","execution_count":32,"metadata":{},"outputs":[{"data":{"image/png":"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","text/plain":["<PIL.Image.Image image mode=RGBA size=591x38 at 0x1626E9986C8>"]},"execution_count":32,"metadata":{},"output_type":"execute_result"}],"source":["import visualkeras\n","visualkeras.layered_view(model)"]},{"cell_type":"code","execution_count":33,"metadata":{},"outputs":[{"data":{"image/png":"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","text/plain":["<PIL.Image.Image image mode=RGBA size=591x74 at 0x1626E99F608>"]},"execution_count":33,"metadata":{},"output_type":"execute_result"}],"source":["visualkeras.layered_view(model, legend=True) # without custom font"]},{"cell_type":"code","execution_count":34,"metadata":{},"outputs":[{"data":{"image/png":"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","text/plain":["<PIL.Image.Image image mode=RGBA size=591x77 at 0x1626E99F708>"]},"execution_count":34,"metadata":{},"output_type":"execute_result"}],"source":["from PIL import ImageFont\n","font = ImageFont.truetype(\"arial.ttf\", 12)\n","visualkeras.layered_view(model, legend=True, font=font) # selected font"]},{"cell_type":"code","execution_count":35,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Model summary saved to 'inception_model_summary.txt'.\n"]}],"source":["# Save the model summary to a text file\n","with open('ALEXORG_model_summary.txt', 'w') as f:\n","    loaded_model.summary(print_fn=lambda x: f.write(x + '\\n'))\n","\n","print(\"Model summary saved to 'inception_model_summary.txt'.\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"}},"nbformat":4,"nbformat_minor":4}
